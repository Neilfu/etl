{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import random\n",
    "from functools import wraps\n",
    "LOG_FILE = '../data/log/etl.log'\n",
    "\n",
    "def initLog(name='ETL'):\n",
    "    handler = logging.handlers.RotatingFileHandler(LOG_FILE, maxBytes = 1024*1024, backupCount = 1000)\n",
    "    fmt = '%(asctime)s - %(filename)s:%(lineno)s - %(name)s - %(message)s'\n",
    "    formatter = logging.Formatter(fmt)   # 实例化formatter  \n",
    "    handler.setFormatter(formatter)      # 为handler添加formatter  \n",
    "\n",
    "    logger = logging.getLogger(name)    # 获取名为tst的logger  \n",
    "    logger.addHandler(handler)           # 为logger添加handler  \n",
    "    logger.setLevel(logging.DEBUG)  \n",
    "    return logger\n",
    "\n",
    "logger = initLog('ETL')\n",
    "logger.setLevel(logging.DEBUG) \n",
    "\n",
    "def logged(message=None,level=logging.DEBUG,name='ETL'):\n",
    "    def decorate(func):\n",
    "        logname = name if name else func.__module__\n",
    "        log = logging.getLogger(logname)\n",
    "        logmsg = message if message else func.__name__\n",
    "        \n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            log.log(level,logmsg)\n",
    "            return func(*args,**kwargs)\n",
    "        return wrapper\n",
    "    return decorate\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('libs/')\n",
    "from table_v3 import TableChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EtlScript(traitlets.HasTraits):\n",
    "    \n",
    "    _supportType = ['float32','float64','float', 'int','int8','int16','int32',\n",
    "                    'int64', 'bool', 'datetime64','timedelta','category','object','dict','list']\n",
    "\n",
    "    #批次读取大小\n",
    "    _chunksize = 1000\n",
    "    _cachepath = '../data/cache/'\n",
    "    _metadata = None\n",
    "    _df = pd.DataFrame()\n",
    "    _data_change=traitlets.Float()\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #虚方法，子类实现\n",
    "    def dataRefreshed(self):\n",
    "        pass\n",
    "    \n",
    "    @logged()\n",
    "    def eventTrigger(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(self,*args, **kwargs):\n",
    "            result = func(self,*args, **kwargs)\n",
    "            self.dataRefreshed()\n",
    "        return wrapper \n",
    "    \n",
    "    @logged()\n",
    "    @eventTrigger\n",
    "    def drop(self,*args,**kwargs):\n",
    "        '''\n",
    "            drop col:column_ref\n",
    "        '''\n",
    "        col_name = kwargs.get('col')\n",
    "        if col_name in self._df:\n",
    "            self._df.drop(col_name,axis=1,inplace=True)\n",
    "        else:\n",
    "            raise Exception('col is not valid, must be in list[{}]'.format(self._df.columns.values.tolist()))\n",
    "\n",
    "    @logged()\n",
    "    @eventTrigger  \n",
    "    def rename(self,*args,**kwargs):\n",
    "        '''\n",
    "            rename: col: column_name to:new_col_name\n",
    "        '''\n",
    "        col_name = kwargs.get('col')\n",
    "        col_new_name = kwargs.get('to')\n",
    "        if col_name in self._df and col_new_name not in self._df:\n",
    "            self._df.rename({col_name:col_new_name},inplace=True,axis='columns')\n",
    "        else:\n",
    "            raise Exception('col name[{}] must be in list{} and new name[{}] must be not'\\\n",
    "                            .format(col_name,self._df.columns.values.tolist(),col_new_name))  \n",
    "            \n",
    "    @logged()\n",
    "    @eventTrigger\n",
    "    def settype(self,*args,**kwargs):\n",
    "        '''\n",
    "            settype col:column_ref to:new_col_type\n",
    "        '''\n",
    "        col_name = kwargs.get('col')\n",
    "        col_new_type = kwargs.get('to')\n",
    "        if col_name not in self._df or col_new_type not in self._supportType:\n",
    "            raise Exception('col name[{}] must be in list{} and new type must be in {} '\\\n",
    "                            .format(col_name,self._df.columns.values.tolist(),col_new_name,self._supportType))  \n",
    "        if col_new_type not in ['dict','list']:\n",
    "            self._df[col_name] = self._df[col_name].astype(col_new_type,errors='ignore')\n",
    "        else:\n",
    "            #todo suppurt dict and list data type\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvData(EtlScript):\n",
    "    \n",
    "   # _supportType = ['float32','float64','float', 'int','int8','int16','int32','int64', 'bool', \n",
    "   #                'datetime64','timedelta','category','object','dict','list']\n",
    "\n",
    "    #批次读取大小\n",
    "    #_chunksize = 1000\n",
    "    #_cachepath = '../data/cache/'\n",
    "    #_df = pd.DataFrame()\n",
    "    #_data_change=traitlets.Float()\n",
    "\n",
    "    #_samples = 10000\n",
    "    _datapath = traitlets.Unicode()\n",
    "    _sep = ','\n",
    "    _header = 0\n",
    "    _codec = None\n",
    "        \n",
    "    @logged()\n",
    "    def __init__(self,datapath,samples=10000,sep=',',header=0,codec='utf8', chunksize=1000,usecache=True,cachepath=None):\n",
    "        if samples and isinstance(samples,int) and (samples>0):\n",
    "            self._samples = samples\n",
    "        if chunksize and isinstance(chunksize,int) and (chunksize>0):\n",
    "            self._chunksize = chunksize\n",
    "        if header and isinstance(header,int) and (header>0):\n",
    "            self._header = header\n",
    "        if isinstance(usecache,bool):\n",
    "            self._usecache = usecache\n",
    "        if sep:\n",
    "            self._sep = sep\n",
    "        if codec:\n",
    "            self._codec = codec\n",
    "        if os.path.isfile(datapath):\n",
    "            self._datapath = datapath\n",
    "            self._linetotal = self.estimateLen()\n",
    "        if cachepath and os.path.isdir(cachepath):\n",
    "            self._cachepath = cachepath\n",
    "\n",
    "    @logged()\n",
    "    def refreshdataType(self):\n",
    "        self._metadata = {}\n",
    "        for col in self._df:\n",
    "            fld = {}\n",
    "            fld['type'] = self._df[col].dtype\n",
    "            fld['sumary'] = self._df[col].describe()\n",
    "            self._metadata[col] = fld\n",
    "                                    \n",
    "                                    \n",
    "    \n",
    "    @logged()\n",
    "    @EtlScript.eventTrigger\n",
    "    def loadSamples(self,samples=None,usecache=True,cachename=None):\n",
    "        if isinstance(usecache,bool):\n",
    "            self._usecache = usecache\n",
    "        if not(self._usecache):\n",
    "            self.takeSamples()\n",
    "        else:\n",
    "            if cachename :\n",
    "                filename = cachename\n",
    "            else:\n",
    "                name = os.path.splitext(os.path.split(self._datapath)[1])[0]\n",
    "                filename = os.path.join(self._cachepath,name+'.hd5')\n",
    "            try:\n",
    "                self._df = pd.read_hdf(filename)\n",
    "                logger.info('success in loading cache from file:{}'.format(filename))\n",
    "            except Exception as err:\n",
    "                logger.exception('fail in loading cache from file:{}\\nbegin taking {} samples,\\nbecause '\n",
    "                                 .format(filename,self._samples,str(err)))              \n",
    "                self.takeSamples()      \n",
    "        self.refreshdataType()\n",
    "        return self\n",
    "\n",
    "    @logged()\n",
    "    def takeSamples(self,samples=None):\n",
    "        logger.debug('begin taking sample')\n",
    "        if samples and isinstance(samples,int) and (samples>0):\n",
    "            self._samples = samples\n",
    "        chunker = pd.read_csv(self._datapath,sep=self._sep,header=self._header,chunksize=self._chunksize,encoding=self._codec)\n",
    "        sampleSize = round(self._samples / (self._linetotal / self._chunksize))\n",
    "        for piece in chunker:\n",
    "            self._df = pd.concat([self._df,piece.sample(n=sampleSize)])\n",
    "        realSize = self._df.shape[0]\n",
    "        last = self._samples - realSize\n",
    "        self._df = pd.concat([self._df,piece.sample(n=last)])\n",
    "        if self._usecache:\n",
    "            self.cacheSamples()\n",
    "        self.object2category()\n",
    "        return self\n",
    "    \n",
    "    @logged()\n",
    "    def cacheSamples(self):\n",
    "        logger.debug('begin caching sample')\n",
    "        name = os.path.splitext(os.path.split(self._datapath)[1])[0]\n",
    "        filename = os.path.join(self._cachepath,name+'.hd5')\n",
    "        if os.access(self._cachepath, os.W_OK):\n",
    "            if not(os.path.isfile(filename)) or os.access(filename,os.W_OK):\n",
    "                self._df.to_hdf(filename,'default')\n",
    "            else:\n",
    "                raise Exception('can not create file:{}'.format(filename))\n",
    "        return self\n",
    "    \n",
    "    @logged()    \n",
    "    def estimateLen(self):\n",
    "        with open(self._datapath) as file:\n",
    "            size = 0\n",
    "            for i,line in enumerate(file):\n",
    "                size = size +len(line)\n",
    "                if i >150:\n",
    "                    break\n",
    "            lineSize = size /150\n",
    "            fileSize = os.path.getsize(self._datapath)\n",
    "            return int(fileSize / lineSize)\n",
    "\n",
    "   \n",
    "    #对object类型的列，若唯一值占比小于50%，则转化为category类型，以节约存储\n",
    "    @logged()\n",
    "    @EtlScript.eventTrigger\n",
    "    def object2category(self):\n",
    "        num_total = self._df.shape[0]\n",
    "        for col in self._df:\n",
    "            if self._df[col].dtype == 'object':\n",
    "                num_unique = len(self._df[col].unique())                \n",
    "                if num_unique < num_total *0.5:\n",
    "                    self._df[col] = self._df[col].astype('category')\n",
    "        #self.dataRefreshed()\n",
    "        return self\n",
    "\n",
    "    @logged()\n",
    "    @EtlScript.eventTrigger\n",
    "    def convertType(self,col,typename):\n",
    "        if typename not in self._supportType:\n",
    "            raise Exception('type must be in list[{}]'.format(','.join( self._supportType)))\n",
    "        if col not in self._df:\n",
    "            raise Exception('col[{}] is not a column of the data'.format(col))\n",
    "        self._df[col] = self._df[col].astype(typename,errors='ignore')\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def header(self):\n",
    "        return self._df.columns.values.tolist()\n",
    "    \n",
    "    @header.setter\n",
    "    @EtlScript.eventTrigger\n",
    "    def header(self,header=[]):\n",
    "        self._df.columns = header\n",
    "        #self.dataRefreshed()\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._df.values.tolist()\n",
    "    \n",
    "    @property\n",
    "    def datatypes(self):\n",
    "        return [self._metadata[f]['type'] for f in self.header]\n",
    "    \n",
    "    #数据更新标识\n",
    "    @logged()\n",
    "    def dataRefreshed(self):\n",
    "        self.refreshdataType()\n",
    "        self._data_change = random.random()\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EtlManager():\n",
    "    \n",
    "    _data = None\n",
    "    _output = None\n",
    "    _show = False\n",
    "    \n",
    "    def __init__(self,path):\n",
    "        self._data = self.loadData(path)\n",
    "        self._output = self.initTable()\n",
    "        self._data.observe(self.eventDatachanged,'_data_change')\n",
    "    \n",
    "    @logged()\n",
    "    def eventDatachanged(self,change):\n",
    "        self.refreshOutput()\n",
    "    \n",
    "    def refreshOutput(self):\n",
    "        header  = zip(self._data.header,self._data.datatypes)\n",
    "        self._output.model.header = [f for f in header]\n",
    "        self._output.model.data = self._data.data\n",
    "    \n",
    "    @logged()\n",
    "    def loadData(self,path,samples=30,chunksize=11,usecache=True):\n",
    "        data = CsvData(path,samples=samples,sep=',',chunksize=chunksize,usecache=usecache)\n",
    "        data.loadSamples()\n",
    "        return data\n",
    "    \n",
    "    def initTable(self):\n",
    "        header  = zip(self._data.header,self._data.datatypes)\n",
    "        return TableChart(header=[f for f in header],body=self._data.data)\n",
    "    \n",
    "    def run(self):\n",
    "        while(True):\n",
    "            self.cmdPrompt()\n",
    "        \n",
    "    def cmdPrompt(self):\n",
    "        pass\n",
    "\n",
    "    def showTable(self,enable=True):\n",
    "        if isinstance(enable,bool):\n",
    "            self._show = enable\n",
    "        else:\n",
    "            raise Exception('display must be bool value')\n",
    "        if self._show:\n",
    "            self.show_handle = display(self._output)\n",
    "        else:\n",
    "            self._output.close()\n",
    "            self._show = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecea0a75fbe453ebc955cbdbb4c386d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = EtlManager('../data/iris.csv')\n",
    "m.showTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m._data.settype(col='species',to='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m._data.rename(col='species',to='kind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m._data.drop(col='sepalLength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
